{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2af633b-4d0f-4b80-b090-2d6429f22e90",
   "metadata": {},
   "source": [
    "# Evaluating RAG Architectures on Benchmark Tasks\n",
    "\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "If you ever wanted to compare different approaches to Q&A over docs, you'll find this notebook helpful to get started evaluating different configurations and common RAG architectures on benchmark tasks. The goal is to make it easy for you to experiment with different techniques, understand their tradeoffs, and make informed decisions for your specific use case.\n",
    "\n",
    "#### What is RAG?\n",
    "\n",
    "LLMs have a knowledge cutoff. For them to accurately respond to user queries, they need access to relevant information. Retrieval Augmented Generation (RAG) (aka \"give an LLM a search engine\") is a common design pattern to address this. The key components are:\n",
    "\n",
    "- Retriever: fetches information from a knowledge base, which can be a vector search engine, a database, or any search engine.\n",
    "- Generator: synthesizes responses using a blend of learned knowledge and the retrieved information.\n",
    "\n",
    "The overall quality of the system depends on both components.\n",
    "\n",
    "\n",
    "#### Benchmark Tasks and Datasets (As of 2023/11/21)\n",
    "\n",
    "The following datasets are currently available:\n",
    "\n",
    "- LangChain Docs Q&A - technical questions based on the LangChain python documentation\n",
    "- Semi-structured Earnings - financial questions and answers on financial PDFs containing tables and graphs\n",
    "\n",
    "Each task comes with a labeled dataset of questions and answers. They also provide configurable factory functions for easy customization of chunking and indexing for the relevant source documents.\n",
    "\n",
    "And with that, let's get started!\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "We will install quite a few prerequisites for this example since we are comparing many techniques and models.\n",
    "\n",
    "We will be using LangSmith to capture the evaluation traces. You can make a free account at [smith.langchain.com](https://smith.langchain.com/). Once you've done so, you can make an API key and set it below.\n",
    "\n",
    "We are comparing many methods throughout this notebook, so the list of dependencies we will install is long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f44b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --quiet langchain langsmith langchainhub langchain_benchmarks\n",
    "%pip install --quiet chromadb openai huggingface pandas langchain_experimental sentence_transformers pyarrow anthropic tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b518cf-99fb-44be-8acb-ee0a8ba62272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"  # Your Anthropic API key\n",
    "# Silence warnings from HuggingFace\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique run ID for these experiments\n",
    "run_uid = uuid.uuid4().hex[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a666d-8bf5-4bfd-8b20-8b7defdb8cd5",
   "metadata": {},
   "source": [
    "## Review Q&A tasks\n",
    "\n",
    "The registry provides configurations to test out common architectures on curated datasets.\n",
    "Below is a list of the available tasks at the time of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3644d211-382e-41aa-b282-21b01d28fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name                   </th><th>Type         </th><th>Dataset ID                                                                                                                                                 </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LangChain Docs Q&A     </td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
       "<tr><td>Semi-structured Reports</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d\" target=\"_blank\" rel=\"noopener\">c47d9617-ab99-4d6e-a6e6-92b8daf85a7d</a></td><td>Questions and answers based on PDFs containing tables and charts.\n",
       "\n",
       "The task provides the raw documents as well as factory methods to easily index them\n",
       "and create a retriever.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
       "<tr><td>Multi-modal slide decks</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d\" target=\"_blank\" rel=\"noopener\">40afc8e7-9d7e-44ed-8971-2cae1eb59731</a></td><td>This public dataset is a work-in-progress and will be extended over time.\n",
       "        \n",
       "Questions and answers based on slide decks containing visual tables and charts.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(tasks=[RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_cached_docs at 0x7fe2283b5d80>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x7fe1fdec0b80>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x7fe1fdec0c10>, 'hyde': <function _chroma_hyde_retriever_factory at 0x7fe1fdec0ca0>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x7fe2283b5f30>}), RetrievalTask(name='Semi-structured Reports', dataset_id='https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d', description=\"Questions and answers based on PDFs containing tables and charts.\\n\\nThe task provides the raw documents as well as factory methods to easily index them\\nand create a retriever.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_docs at 0x7fe1fdec1360>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x7fe1fdec1480>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x7fe1fdec1510>, 'hyde': <function _chroma_hyde_retriever_factory at 0x7fe1fdec15a0>}, architecture_factories={}), RetrievalTask(name='Multi-modal slide decks', dataset_id='https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d', description='This public dataset is a work-in-progress and will be extended over time.\\n        \\nQuestions and answers based on slide decks containing visual tables and charts.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\n', get_docs={}, retriever_factories={}, architecture_factories={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.filter(Type=\"RetrievalTask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671282f8-c455-4390-b018-e53bbd833093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name                  </td><td>LangChain Docs Q&A                                                                                                                                         </td></tr>\n",
       "<tr><td>Type                  </td><td>RetrievalTask                                                                                                                                              </td></tr>\n",
       "<tr><td>Dataset ID            </td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td></tr>\n",
       "<tr><td>Description           </td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).                                                                                                                                                            </td></tr>\n",
       "<tr><td>Retriever Factories   </td><td>basic, parent-doc, hyde                                                                                                                                    </td></tr>\n",
       "<tr><td>Architecture Factories</td><td>conversational-retrieval-qa                                                                                                                                </td></tr>\n",
       "<tr><td>get_docs              </td><td><function load_cached_docs at 0x7fe2283b5d80>                                                                                                              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_cached_docs at 0x7fe2283b5d80>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x7fe1fdec0b80>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x7fe1fdec0c10>, 'hyde': <function _chroma_hyde_retriever_factory at 0x7fe1fdec0ca0>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x7fe2283b5f30>})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_docs = registry[\"LangChain Docs Q&A\"]\n",
    "langchain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset LangChain Docs Q&A already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/2586a6b8-a802-5f6f-b08e-ef250f997c21/datasets/1013d34f-58c9-44f4-974b-69d7c9c6b90d.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(langchain_docs.dataset_id, dataset_name=langchain_docs.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02011398-1a6f-42c1-b586-9d01c78e3ee4",
   "metadata": {},
   "source": [
    "## Basic Vector Retrieval\n",
    "\n",
    "For our first example, we will generate a single embedding for each document in the dataset,\n",
    "without chunking or indexing, and then provide that retriever to an LLM for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58247f5-b9bd-4cc5-9632-78bc21bb10b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8423f2a4fc8a45fabc304d23a7640eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "# Indexes the documents with the specified embeddings\n",
    "# Note that this does not apply any chunking to the docs,\n",
    "# which means the documents can be of arbitrary length\n",
    "retriever = retriever_factory(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d2e139-2653-4f7b-944b-91ef52f43d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Factory for creating a conversational retrieval QA chain\n",
    "\n",
    "chain_factory = langchain_docs.architecture_factories[\"conversational-retrieval-qa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9be718-64f0-4706-9527-240a1cdb3ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- **LangChain Expression Language (LCEL)** is a declarative framework for composing chains effortlessly in LangChain.\\n- It allows for seamless production deployment without code changes, supporting both synchronous and asynchronous operations.\\n- Key features include streaming support, optimized parallel execution, retries, and access to intermediate results.\\n- LCEL provides built-in input and output schemas for validation and integrates with LangSmith for observability and debugging purposes [1][2].'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain_factory(retriever, llm=llm).invoke({\"question\": \"what's lcel?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab7514e-a6ef-4c21-b90f-d9cbefcf5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'gpt-4o-mini qa-chain simple-index c7f362' at:\n",
      "https://smith.langchain.com/o/2586a6b8-a802-5f6f-b08e-ef250f997c21/datasets/1013d34f-58c9-44f4-974b-69d7c9c6b90d/compare?selectedSessions=58552e7a-f159-4b23-b7c5-5b0064f6d862\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "https://smith.langchain.com/o/2586a6b8-a802-5f6f-b08e-ef250f997c21/datasets/1013d34f-58c9-44f4-974b-69d7c9c6b90d\n",
      "[------------------>                               ] 32/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 889610d7-372b-41e2-8e41-94610316b1d5 with inputs {'question': 'What does ReAct mean?'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4IzJSGSSKpWz7EAf8b3xiI4d on tokens per min (TPM): Limit 60000, Used 54438, Requested 8433. Please try again in 2.871s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------->                      ] 48/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example a5d83982-2a01-4f85-9413-2c8e007f7a10 with inputs {'question': 'What is a chain?'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4IzJSGSSKpWz7EAf8b3xiI4d on tokens per min (TPM): Limit 60000, Used 50718, Requested 25391. Please try again in 16.109s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------->                      ] 49/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example c54c777a-effb-450e-b918-2d0c8c8c94b4 with inputs {'question': 'how do I search and filter metadata in redis vectorstore?'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4IzJSGSSKpWz7EAf8b3xiI4d on tokens per min (TPM): Limit 60000, Used 54128, Requested 17248. Please try again in 11.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------------------->                 ] 57/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example c823482b-7ff4-4608-9ef1-755f2cd6be7d with inputs {'question': 'I am summarizing text contained in the variable chunks with load_summarize_chain.\\n\\nchain = load_summarize_chain(llm, chain_type=\"map_reduce\")\\nchain.run(chunks)\\nI would like to add a tag when I run the chain that langsmith will capture. How?'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4IzJSGSSKpWz7EAf8b3xiI4d on tokens per min (TPM): Limit 60000, Used 58551, Requested 10076. Please try again in 8.627s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------->                ] 58/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example a3862471-ca59-4a2a-abc6-e68bf6b235b7 with inputs {'question': 'what method should subclasses override if they can start producing output while input is still being generated'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4IzJSGSSKpWz7EAf8b3xiI4d on tokens per min (TPM): Limit 60000, Used 58009, Requested 16734. Please try again in 14.743s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------------------------->           ] 67/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 05c63d4a-82dd-419b-93ca-fed10e31d000 with inputs {'question': 'how do i run llama on vllm'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4IzJSGSSKpWz7EAf8b3xiI4d on tokens per min (TPM): Limit 60000, Used 48390, Requested 13634. Please try again in 2.023s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------------------------->        ] 73/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 3f8cde09-979b-47db-b73f-b689dc40748f with inputs {'question': 'what does runnable.predict() mean?'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-4IzJSGSSKpWz7EAf8b3xiI4d on tokens per min (TPM): Limit 60000, Used 53432, Requested 23084. Please try again in 16.516s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 86/86"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.score_string:accuracy</th>\n",
       "      <th>feedback.embedding_cosine_distance</th>\n",
       "      <th>feedback.faithfulness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Error code: 429 - {'error': {'message': 'Rate ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fe4e150f-ab80-4b62-9b81-6772b0813364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.179077</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.332186</td>\n",
       "      <td>0.090606</td>\n",
       "      <td>0.340946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.025230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.024488</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.074388</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.188493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.109492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.259451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.214402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.905194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.565641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.score_string:accuracy  feedback.embedding_cosine_distance  \\\n",
       "count                        79.000000                           79.000000   \n",
       "unique                             NaN                                 NaN   \n",
       "top                                NaN                                 NaN   \n",
       "freq                               NaN                                 NaN   \n",
       "mean                          0.569620                            0.144144   \n",
       "std                           0.332186                            0.090606   \n",
       "min                           0.100000                            0.024488   \n",
       "25%                           0.200000                            0.074388   \n",
       "50%                           0.700000                            0.109492   \n",
       "75%                           0.700000                            0.214402   \n",
       "max                           1.000000                            0.333093   \n",
       "\n",
       "        feedback.faithfulness  \\\n",
       "count               41.000000   \n",
       "unique                    NaN   \n",
       "top                       NaN   \n",
       "freq                      NaN   \n",
       "mean                 0.702439   \n",
       "std                  0.340946   \n",
       "min                  0.100000   \n",
       "25%                  0.300000   \n",
       "50%                  1.000000   \n",
       "75%                  1.000000   \n",
       "max                  1.000000   \n",
       "\n",
       "                                                    error  execution_time  \\\n",
       "count                                                   7       86.000000   \n",
       "unique                                                  7             NaN   \n",
       "top     Error code: 429 - {'error': {'message': 'Rate ...             NaN   \n",
       "freq                                                    1             NaN   \n",
       "mean                                                  NaN        5.179077   \n",
       "std                                                   NaN        6.025230   \n",
       "min                                                   NaN        0.991064   \n",
       "25%                                                   NaN        2.188493   \n",
       "50%                                                   NaN        3.259451   \n",
       "75%                                                   NaN        4.905194   \n",
       "max                                                   NaN       33.565641   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     86  \n",
       "unique                                    86  \n",
       "top     fe4e150f-ab80-4b62-9b81-6772b0813364  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from langsmith.client import Client\n",
    "from langchain_benchmarks.rag import get_eval_config\n",
    "\n",
    "client = Client()\n",
    "RAG_EVALUATION = get_eval_config()\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    project_name=f\"gpt-4o-mini qa-chain simple-index {run_uid}\",\n",
    "    project_metadata={\n",
    "        \"index_method\": \"basic\",\n",
    "        \"embedding_model\": \"text-embedding-3-small\",\n",
    "        \"llm\": \"gpt-4o-mini\",\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86578d5-be5c-4bcd-9dcb-35280eeed3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.score_string:accuracy</th>\n",
       "      <th>feedback.embedding_cosine_distance</th>\n",
       "      <th>feedback.faithfulness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Error code: 400 - {'error': {'message': \"This ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3c7beec6-78dd-452c-96e2-d5a7e42f115e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.529508</td>\n",
       "      <td>0.125739</td>\n",
       "      <td>0.740541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.728728</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.287138</td>\n",
       "      <td>0.064135</td>\n",
       "      <td>0.316631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.161951</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.031547</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.075807</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.345414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.112076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.590454</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.169307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.845377</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.507141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.score_string:accuracy  feedback.embedding_cosine_distance  \\\n",
       "count                        61.000000                           61.000000   \n",
       "unique                             NaN                                 NaN   \n",
       "top                                NaN                                 NaN   \n",
       "freq                               NaN                                 NaN   \n",
       "mean                          0.529508                            0.125739   \n",
       "std                           0.287138                            0.064135   \n",
       "min                           0.100000                            0.031547   \n",
       "25%                           0.300000                            0.075807   \n",
       "50%                           0.500000                            0.112076   \n",
       "75%                           0.700000                            0.169307   \n",
       "max                           1.000000                            0.283641   \n",
       "\n",
       "        feedback.faithfulness  \\\n",
       "count               37.000000   \n",
       "unique                    NaN   \n",
       "top                       NaN   \n",
       "freq                      NaN   \n",
       "mean                 0.740541   \n",
       "std                  0.316631   \n",
       "min                  0.100000   \n",
       "25%                  0.500000   \n",
       "50%                  1.000000   \n",
       "75%                  1.000000   \n",
       "max                  1.000000   \n",
       "\n",
       "                                                    error  execution_time  \\\n",
       "count                                                  25       86.000000   \n",
       "unique                                                 25             NaN   \n",
       "top     Error code: 400 - {'error': {'message': \"This ...             NaN   \n",
       "freq                                                    1             NaN   \n",
       "mean                                                  NaN        8.728728   \n",
       "std                                                   NaN        8.161951   \n",
       "min                                                   NaN        0.818421   \n",
       "25%                                                   NaN        2.345414   \n",
       "50%                                                   NaN        5.590454   \n",
       "75%                                                   NaN       12.845377   \n",
       "max                                                   NaN       38.507141   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     86  \n",
       "unique                                    86  \n",
       "top     3c7beec6-78dd-452c-96e2-d5a7e42f115e  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee992f87-4137-49b1-a1f1-0cc7be0e32d8",
   "metadata": {},
   "source": [
    "# Comparing with other indexing strategies\n",
    "\n",
    "The index used above retrieves the raw documents based on a single vector per document. It doesn't perform any additional chunking. You can try changing the chunking parameters when generating the index.\n",
    "\n",
    "## Customizing Chunking\n",
    "\n",
    "The simplest change you can make to the index is configure how you split the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72030d4-c201-44b8-85cd-903afa313f11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43849e6de97d42ce91ca61dae8f5f8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def transform_docs(docs):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)\n",
    "    yield from splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Used for the cache\n",
    "transformation_name = \"recursive-text-cs4k-ol200\"\n",
    "\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "\n",
    "chunked_retriever = retriever_factory(\n",
    "    embeddings,\n",
    "    transform_docs=transform_docs,\n",
    "    transformation_name=transformation_name,\n",
    "    search_kwargs={\"k\": 4},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74f12f9-1ba6-4bf7-a850-4073fb0994f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'gpt-4o-mini qa-chain chunked c7f362' at:\n",
      "https://smith.langchain.com/o/2586a6b8-a802-5f6f-b08e-ef250f997c21/datasets/1013d34f-58c9-44f4-974b-69d7c9c6b90d/compare?selectedSessions=0eed58cc-7bd8-4d83-be61-308cf5805bf8\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "https://smith.langchain.com/o/2586a6b8-a802-5f6f-b08e-ef250f997c21/datasets/1013d34f-58c9-44f4-974b-69d7c9c6b90d\n",
      "[------------------------------------------------->] 86/86"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.score_string:accuracy</th>\n",
       "      <th>feedback.embedding_cosine_distance</th>\n",
       "      <th>feedback.faithfulness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8cdb410d-1a7d-48a1-9731-33db316e4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509302</td>\n",
       "      <td>0.158267</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.014470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.338727</td>\n",
       "      <td>0.096378</td>\n",
       "      <td>0.372759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.320374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.029314</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896467</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.077053</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.053875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.121169</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.910915</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.263016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.781327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.267225</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.score_string:accuracy  feedback.embedding_cosine_distance  \\\n",
       "count                        86.000000                           86.000000   \n",
       "unique                             NaN                                 NaN   \n",
       "top                                NaN                                 NaN   \n",
       "freq                               NaN                                 NaN   \n",
       "mean                          0.509302                            0.158267   \n",
       "std                           0.338727                            0.096378   \n",
       "min                           0.100000                            0.029314   \n",
       "25%                           0.100000                            0.077053   \n",
       "50%                           0.500000                            0.121169   \n",
       "75%                           0.700000                            0.263016   \n",
       "max                           1.000000                            0.347211   \n",
       "\n",
       "        feedback.faithfulness error  execution_time  \\\n",
       "count               51.000000     0       86.000000   \n",
       "unique                    NaN     0             NaN   \n",
       "top                       NaN   NaN             NaN   \n",
       "freq                      NaN   NaN             NaN   \n",
       "mean                 0.650980   NaN        3.014470   \n",
       "std                  0.372759   NaN        1.320374   \n",
       "min                  0.100000   NaN        0.896467   \n",
       "25%                  0.300000   NaN        2.053875   \n",
       "50%                  0.700000   NaN        2.910915   \n",
       "75%                  1.000000   NaN        3.781327   \n",
       "max                  1.000000   NaN        8.267225   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     86  \n",
       "unique                                    86  \n",
       "top     8cdb410d-1a7d-48a1-9731-33db316e4820  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunked_results = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, chunked_retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    project_name=f\"gpt-4o-mini qa-chain chunked {run_uid}\",\n",
    "    project_metadata={\n",
    "        \"index_method\": \"basic\",\n",
    "        \"chunk_size\": 4000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"embedding_model\": \"text-embedding-3-small\",\n",
    "        \"llm\": \"gpt-4o-mini\",\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d825f1-9a91-429d-bf3e-a9b9c2785a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunked_results.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a62ec-9a9c-4d7a-ab90-97020d855ee7",
   "metadata": {},
   "source": [
    "## Parent Document Retriever\n",
    "\n",
    "This indexing technique chunks documents and generates 1 vector per chunk.\n",
    "At retrieval time, the K \"most similar\" chunks are fetched, then the full parent documents are returned for the LLM to reason over.\n",
    "\n",
    "This ensures the chunk is surfaced in its full natural context. It also can potentially improve the initial retrieval quality since the similarity scores are scoped to individual chunks.\n",
    "\n",
    "Let's see if this technique is effective in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398f5e3-b7fe-4693-bcc0-c6c6f75c8234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever_factory = langchain_docs.retriever_factories[\"parent-doc\"]\n",
    "\n",
    "# Indexes the documents with the specified embeddings\n",
    "parent_doc_retriever = retriever_factory(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f4b5d-143a-44ce-95f4-d0b5782ada74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_doc_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, parent_doc_retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    project_name=f\"claude-2 qa-chain parent-doc {run_uid}\",\n",
    "    project_metadata={\n",
    "        \"index_method\": \"parent-doc\",\n",
    "        \"embedding_model\": \"thenlper/gte-base\",\n",
    "        \"llm\": \"claude-2\",\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef0410-47ec-4830-9b75-621eb85240ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_doc_test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b27dd0-f0df-4551-a972-1a6c0df5ffb9",
   "metadata": {},
   "source": [
    "## HyDE\n",
    "\n",
    "HyDE (Hypothetical document embeddings) refers to the technique of using an LLM\n",
    "to generate example queries that my be used to retrieve a doc. By doing so, the resulting embeddings are automatically \"more aligned\" with the embeddings generated from the query. This comes with an additional indexing cost, since each document requires an additoinal call to an LLM while indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92d2c2-f410-43cc-9c9f-abc22ef48353",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_factory = langchain_docs.retriever_factories[\"hyde\"]\n",
    "\n",
    "retriever = retriever_factory(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2179cf29-2d75-4a04-bbb5-b8f22028fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, retriever=retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    "    project_name=f\"claude-2 qa-chain HyDE {run_uid}\",\n",
    "    project_metadata={\n",
    "        \"index_method\": \"HyDE\",\n",
    "        \"embedding_model\": \"thenlper/gte-base\",\n",
    "        \"llm\": \"claude-2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a04f21-0308-4b00-a6f1-694d98ba7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_test_run.get_aggregate_feedback()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
