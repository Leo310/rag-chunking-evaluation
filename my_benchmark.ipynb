{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Evaluation Approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/my_approach.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict, TypedDict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = load_dotenv()\n",
    "\n",
    "data_dir = \"my_benchmark/\"\n",
    "os.environ['CHUNKING_BENCHMARK'] = data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and Save Documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each document is loaded as one Langchain document possibly to small to fit into a LLM. Therefore, we need to split these documents into smaller pieces of text for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import save_documents\n",
    "\n",
    "documents: List[Document] = []\n",
    "for file in os.listdir(data_dir+\"documents\"):\n",
    "    file_path = os.path.join(data_dir+\"documents\", file)\n",
    "    loader = TextLoader(file_path)\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "save_documents(documents, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import load_documents\n",
    "documents = load_documents(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apply chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i chunking_strategies.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import load_chunks\n",
    "split_chunks: Dict[str, Document] = load_chunks(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ingest into vector store\n",
    "\n",
    "Using FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c75dd8198e4fee8e1042766078f026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72875bac5f004acea8eb89ce5cb907ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdc5ccf07cb4e6286d148a247ba7181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/84.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064c2a750a1041a09e04abcf119ae8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/107 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f222b6c953f04553956eaab27bf60bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732cfa54c91b4a4a86c9b6e55cfd5431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb089b2fd9745bcb54b95823dcc66ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3243540889483cab65367efcf59a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36499d0635c4c2186a170cf7fabcb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7c9da339bc46a78dd063cfa78ad2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bc38fdcb194bb2a1ffd74f1506b9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing markdown-header-recursive-512-0\n",
      "Indexing fixed-size-2048-0\n",
      "Indexing markdown-header-recursive-1024-0\n",
      "Indexing markdown-header-recursive-2048-200\n",
      "Indexing recursive-1024-200\n",
      "Indexing fixed-size-512-0\n",
      "Indexing fixed-size-1024-0\n",
      "Indexing markdown-header-recursive-1024-200\n",
      "Indexing markdown-header-recursive-2048-0\n",
      "Indexing fixed-size-1024-200\n",
      "Indexing markdown-header\n",
      "Indexing recursive-2048-0\n",
      "Indexing fixed-size-2048-200\n",
      "Indexing recursive-512-200\n",
      "Indexing recursive-2048-200\n",
      "Indexing recursive-1024-0\n",
      "Indexing fixed-size-512-200\n",
      "Indexing semantic-chunks-95-recursive-2048-200\n",
      "Indexing semantic-chunks-90\n",
      "Indexing semantic-chunks-95\n",
      "Indexing recursive-512-0\n",
      "Indexing markdown-header-recursive-512-200\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "vector_stores: Dict[str, VectorStore] = {}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"Snowflake/snowflake-arctic-embed-l\",\n",
    "    model_kwargs={\"device\": 0, 'trust_remote_code': True},  # Comment out to use CPU\n",
    ")\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_store_dir = f\"{data_dir}vector_stores/{embeddings.model_name.replace('/', '-')}\"\n",
    "Path(vector_store_dir).mkdir(parents=True, exist_ok=True)\n",
    "for experiment_name, chunks in split_chunks.items():\n",
    "    if os.path.exists(f\"{vector_store_dir}/{experiment_name}\"):\n",
    "        print(\"Loading\", experiment_name)\n",
    "        vector_stores[experiment_name] = FAISS.load_local(f\"{vector_store_dir}/{experiment_name}\", embeddings, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        print(\"Indexing\", experiment_name)\n",
    "        vector_stores[experiment_name] = FAISS.from_documents(chunks, embeddings)\n",
    "        vector_stores[experiment_name].save_local(f\"{vector_store_dir}/{experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Golden Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Evaluation Golden Datasets for each Chunking Strategy should include the following:\n",
    "\n",
    "- Questions across Documents\n",
    "- Ground Truth Chunks (with graded Relevance)\n",
    "- Ground Truth Answers\n",
    "\n",
    "For Simple, Reasoning and Multi-Context Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import GoldenTestset\n",
    "\n",
    "class Questions(TypedDict):\n",
    "    simple: List[GoldenTestset]\n",
    "    reasoning: List[GoldenTestset]\n",
    "    multi_context: List[GoldenTestset]\n",
    "\n",
    "gold_dataset: Dict[str, Questions]  = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create golden dataset on subset of documents, to have some irrelevant documents left for some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_subset_sources = [data_dir+\"documents/sleep.md\", data_dir+\"documents/teeth.md\", data_dir+\"documents/time_management.md\", data_dir+\"documents/mentoring.md\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Generation with RAGAS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate synthetic Questions across Documents to challenge chunking strategies on multi-context queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "environ[\"RAGAS_DO_NOT_TRACK\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83488d2319fb471283241d778b913912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620b257bf4ca47d2af6d5db7c02ca6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embeddings)\n",
    "\n",
    "ragas_testset = generator.generate_with_langchain_docs(\n",
    "    [document for document in documents if document.metadata[\"source\"] in documents_subset_sources],\n",
    "    test_size=10,\n",
    "    distributions={simple: 0.4, reasoning: 0.4, multi_context: 0.2},\n",
    ")\n",
    "df = ragas_testset.to_pandas()\n",
    "df = df.drop(columns=[\"contexts\"]) # ground truth contexts/chunks are determined in next step\n",
    "df.to_csv(data_dir+\"ragas_testset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_testset = pd.read_csv(data_dir+\"ragas_testset.csv\")\n",
    "for experiment_name in split_chunks.keys():\n",
    "    gold_dataset[experiment_name] = {\n",
    "        \"simple\": [],\n",
    "        \"reasoning\": [],\n",
    "        \"multi_context\": []\n",
    "    }\n",
    "    for _, row in ragas_testset.iterrows():\n",
    "        testset = {\n",
    "            \"question\": row['question'],\n",
    "            \"source\": row['metadata'],\n",
    "            \"ground_truth_chunks\": {},\n",
    "            \"ground_truth_answer\": row['ground_truth']\n",
    "        }\n",
    "        gold_dataset[experiment_name][row[\"evolution_type\"]].append(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Relevancy Score for each chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevancy Prompt is taken by Trulens. The difference is that I apply it to all chunks whereas Trulens only computed it on the retrieved chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for markdown-header-recursive-512-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:43<00:00, 10.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:59<00:00, 14.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:17<00:00,  8.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for fixed-size-2048-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:04<00:12,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:14<00:15,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:23<00:08,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:30<00:00,  7.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:06<00:06,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for markdown-header-recursive-1024-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:09<00:28,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:19<00:19,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:26<00:08,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:37<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:06<00:19,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:23<00:25, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:40<00:14, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:49<00:00, 12.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:09<00:09,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:16<00:00,  8.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for markdown-header-recursive-2048-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:25,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:16<00:16,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:21<00:06,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:33<00:00,  8.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:03<00:09,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:13<00:14,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:25<00:09,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:34<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:07<00:07,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for recursive-1024-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:11<00:34, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:21<00:21, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:30<00:09,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:40<00:00, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:25<00:26, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:41<00:14, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:52<00:00, 13.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:10<00:10, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for fixed-size-512-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:13<00:40, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:52<00:00, 13.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:10<00:32, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:32<00:34, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:54<00:19, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:07<00:00, 16.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:24<00:00, 12.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for fixed-size-1024-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:09<00:29,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:19<00:18,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:25<00:07,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:34<00:00,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:07<00:23,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:21<00:22, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:34<00:12, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:43<00:00, 10.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:08<00:08,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:20<00:00, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for markdown-header-recursive-1024-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:07<00:22,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:18<00:19,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:27<00:09,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:40<00:00, 10.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:09<00:27,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:24<00:26, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:42<00:15, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:54<00:00, 13.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:13<00:13, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for markdown-header-recursive-2048-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:24,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:14<00:14,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:21<00:07,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:04<00:13,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:15<00:16,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:32<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:07<00:07,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:13<00:00,  6.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for fixed-size-1024-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:11<00:33, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:22<00:22, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:30<00:09,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:41<00:00, 10.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:10<00:31, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:25<00:26, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:42<00:14, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:55<00:00, 13.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:08<00:08,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:18<00:00,  9.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for markdown-header\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:19<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:23<00:00,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for recursive-2048-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:06<00:20,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:13<00:13,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:18<00:05,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:25<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:06<00:20,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:15<00:15,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:25<00:09,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:32<00:00,  8.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:06<00:06,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for fixed-size-2048-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:26,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:14<00:13,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:20<00:06,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:03<00:11,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:18<00:20, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:26<00:09,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:33<00:00,  8.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:06<00:06,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for recursive-512-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:19<00:57, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:37<00:37, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:53<00:17, 17.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:12<00:00, 18.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:15<00:46, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:47<00:50, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:20<00:28, 28.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:39<00:00, 24.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:18<00:18, 18.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:34<00:00, 17.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for recursive-2048-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:06<00:20,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:14<00:15,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:18<00:05,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:25<00:00,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:05<00:16,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:17<00:18,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:26<00:09,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:33<00:00,  8.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:06<00:06,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for recursive-1024-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:09<00:27,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:20<00:20, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:27<00:08,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:37<00:00,  9.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:25,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:40<00:14, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:50<00:00, 12.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:10<00:10, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:18<00:00,  9.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for fixed-size-512-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:22<01:07, 22.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:02<00:20, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:25<00:00, 21.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:17<00:51, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:52<00:55, 27.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:27<00:31, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:50<00:00, 27.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:22<00:22, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:39<00:00, 19.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for semantic-chunks-95-recursive-2048-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:24,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:17<00:17,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:24<00:08,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:33<00:00,  8.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:04<00:13,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:20<00:22, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:30<00:10, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:38<00:00,  9.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:09<00:09,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:14<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for semantic-chunks-90\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:25,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:17<00:17,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:24<00:07,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:32<00:00,  8.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:07<00:21,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:18<00:19,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 2 seconds\n",
      "Rate limited, waiting 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:39<00:00,  9.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:08<00:08,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:15<00:00,  7.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for semantic-chunks-95\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:06<00:18,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:12<00:12,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:23<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:04<00:14,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:14<00:15,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:06<00:06,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for recursive-512-0\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:17<00:51, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:35<00:35, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:08<00:00, 17.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:14<00:43, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:12<00:25, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:30<00:00, 22.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:18<00:18, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:32<00:00, 16.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for markdown-header-recursive-512-200\n",
      "Collecting ground truth for simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:21<01:04, 21.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:59<00:19, 19.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:21<00:00, 20.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:16<00:50, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:49<00:52, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:44<00:00, 26.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ground truth for multi_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:21<00:21, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited, waiting 1 seconds\n",
      "Rate limited, waiting 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:38<00:00, 19.37s/it]\n",
      "100%|██████████| 2/2 [00:38<00:00, 19.37s/it]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from utils.llm_output_parser import re_0_10_rating\n",
    "\n",
    "system_prompt = \"\"\"You are a RELEVANCE grader; providing the relevance of the given CONTEXT to the given QUESTION.\n",
    "    Respond only as a number from 0 to 10 where 0 is the least relevant and 10 is the most relevant. \n",
    "\n",
    "    A few additional scoring guidelines:\n",
    "\n",
    "    - Long CONTEXTS should score equally well as short CONTEXTS.\n",
    "\n",
    "    - RELEVANCE score should increase as the CONTEXTS provides more RELEVANT context to the QUESTION.\n",
    "\n",
    "    - RELEVANCE score should increase as the CONTEXTS provides RELEVANT context to more parts of the QUESTION.\n",
    "\n",
    "    - CONTEXT that is RELEVANT to some of the QUESTION should score of 2, 3 or 4. Higher score indicates more RELEVANCE.\n",
    "\n",
    "    - CONTEXT that is RELEVANT to most of the QUESTION should get a score of 5, 6, 7 or 8. Higher score indicates more RELEVANCE.\n",
    "\n",
    "    - CONTEXT that is RELEVANT to the entire QUESTION should get a score of 9 or 10. Higher score indicates more RELEVANCE.\n",
    "\n",
    "    - CONTEXT must be relevant and helpful for answering the entire QUESTION to get a score of 10.\n",
    "\n",
    "    - Never elaborate.\"\"\"\n",
    "\n",
    "user_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"QUESTION: {question}\n",
    "\n",
    "    CONTEXT: {context}\n",
    "    \n",
    "    RELEVANCE: \"\"\"\n",
    ")\n",
    "\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def make_request_with_backoff(messages, retries=8):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = critic_llm.invoke(messages)\n",
    "            return response\n",
    "        except openai.RateLimitError as e:\n",
    "            if i == retries - 1:\n",
    "                raise e\n",
    "            wait_time = 2**i\n",
    "            print(f\"Rate limited, waiting {wait_time} seconds\")\n",
    "            time.sleep(wait_time)\n",
    "        except openai.APIError as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "def process_chunk(chunk, testset):\n",
    "    if chunk.metadata[\"source\"] not in testset[\"source\"]:\n",
    "        return None, None\n",
    "\n",
    "    judge_chunk_relevancy_prompt = user_prompt.format(\n",
    "        question=testset[\"question\"], context=chunk.page_content\n",
    "    )\n",
    "\n",
    "    llm_messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=judge_chunk_relevancy_prompt),\n",
    "    ]\n",
    "    response = make_request_with_backoff(llm_messages)\n",
    "    chunk_relevancy = re_0_10_rating(response.content)\n",
    "    if chunk_relevancy != 0.0:\n",
    "        return str(chunk.metadata[\"id\"]), chunk_relevancy\n",
    "    return None, None\n",
    "\n",
    "for experiment_name, questions in gold_dataset.items():\n",
    "    print(\"Collecting ground truth for\", experiment_name)\n",
    "    for question_type, testsets in questions.items():\n",
    "        print(\"Collecting ground truth for\", question_type)\n",
    "        for testset in tqdm(testsets):\n",
    "            ground_truth = {}\n",
    "            with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "                future_to_chunk = {\n",
    "                    executor.submit(process_chunk, chunk, testset): chunk\n",
    "                    for chunk in split_chunks[experiment_name]\n",
    "                }\n",
    "                for future in as_completed(future_to_chunk):\n",
    "                    chunk_id, relevancy = future.result()\n",
    "                    if chunk_id and relevancy:\n",
    "                        ground_truth[chunk_id] = relevancy\n",
    "            \n",
    "            if len(ground_truth):\n",
    "                testset[\"ground_truth_chunks\"] = ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Evaluation Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir+'gold_dataset.json', 'w') as jsonl_file:\n",
    "    json.dump(gold_dataset, jsonl_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Evaluation Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dataset = {}\n",
    "with open(data_dir+'gold_dataset.json', 'r') as jsonl_file:\n",
    "    gold_dataset = json.load(jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import calculate_metrics, calculate_mean_metrics\n",
    "\n",
    "results = pd.DataFrame(columns=[\"experiment_name\", \"question_type\", \"precision\", \"recall\", \"ndcg\"])\n",
    "\n",
    "for experiment_name, questions in gold_dataset.items():\n",
    "    if experiment_name not in vector_stores:\n",
    "        continue\n",
    "    \n",
    "    K = 10 \n",
    "    retriever = vector_stores[experiment_name].as_retriever(search_kwargs={\"k\": K})\n",
    "    for question_type, testsets in questions.items():\n",
    "        metrics = []\n",
    "        for testset in testsets:\n",
    "            question = testset[\"question\"]\n",
    "            ground_truth = testset[\"ground_truth_chunks\"]\n",
    "            K = len(ground_truth)\n",
    "            retriever = vector_stores[experiment_name].as_retriever(search_kwargs={\"k\": K})\n",
    "            retrieved_chunks = retriever.invoke(question)\n",
    "            retrieved_chunk_ids = [str(doc.metadata[\"id\"]) for doc in retrieved_chunks]\n",
    "            metrics.append(calculate_metrics(retrieved_chunk_ids, ground_truth_chunks=list(ground_truth.keys()), ground_truth_relevancies=list(ground_truth.values()), K=K))\n",
    "        \n",
    "        mean_metrics = calculate_mean_metrics(metrics)\n",
    "        \n",
    "        results.loc[len(results)] = [\n",
    "            experiment_name,\n",
    "            question_type,\n",
    "            mean_metrics[\"precision\"],\n",
    "            mean_metrics[\"recall\"],\n",
    "            mean_metrics[\"ndcg\"]\n",
    "        ]\n",
    "\n",
    "results.to_csv(data_dir+\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed-size-2048-200</th>\n",
       "      <td>0.841915</td>\n",
       "      <td>0.841915</td>\n",
       "      <td>0.884327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed-size-2048-0</th>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.882625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recursive-2048-0</th>\n",
       "      <td>0.863806</td>\n",
       "      <td>0.863806</td>\n",
       "      <td>0.873765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markdown-header-recursive-2048-200</th>\n",
       "      <td>0.805336</td>\n",
       "      <td>0.805336</td>\n",
       "      <td>0.863841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed-size-1024-200</th>\n",
       "      <td>0.767514</td>\n",
       "      <td>0.767514</td>\n",
       "      <td>0.841550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markdown-header-recursive-2048-0</th>\n",
       "      <td>0.724237</td>\n",
       "      <td>0.724237</td>\n",
       "      <td>0.838231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recursive-2048-200</th>\n",
       "      <td>0.828538</td>\n",
       "      <td>0.828538</td>\n",
       "      <td>0.835953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markdown-header</th>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.811778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semantic-chunks-95</th>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.810884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed-size-1024-0</th>\n",
       "      <td>0.762517</td>\n",
       "      <td>0.762517</td>\n",
       "      <td>0.797328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recursive-1024-0</th>\n",
       "      <td>0.711180</td>\n",
       "      <td>0.711180</td>\n",
       "      <td>0.791921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semantic-chunks-95-recursive-2048-200</th>\n",
       "      <td>0.770040</td>\n",
       "      <td>0.770040</td>\n",
       "      <td>0.779158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recursive-1024-200</th>\n",
       "      <td>0.701689</td>\n",
       "      <td>0.701689</td>\n",
       "      <td>0.774712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed-size-512-0</th>\n",
       "      <td>0.696388</td>\n",
       "      <td>0.696388</td>\n",
       "      <td>0.754399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed-size-512-200</th>\n",
       "      <td>0.687977</td>\n",
       "      <td>0.687977</td>\n",
       "      <td>0.748491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markdown-header-recursive-1024-200</th>\n",
       "      <td>0.702960</td>\n",
       "      <td>0.702960</td>\n",
       "      <td>0.736516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recursive-512-0</th>\n",
       "      <td>0.660700</td>\n",
       "      <td>0.660700</td>\n",
       "      <td>0.732745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markdown-header-recursive-512-200</th>\n",
       "      <td>0.643205</td>\n",
       "      <td>0.643205</td>\n",
       "      <td>0.732594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recursive-512-200</th>\n",
       "      <td>0.677771</td>\n",
       "      <td>0.677771</td>\n",
       "      <td>0.731007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markdown-header-recursive-1024-0</th>\n",
       "      <td>0.671362</td>\n",
       "      <td>0.671362</td>\n",
       "      <td>0.707776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markdown-header-recursive-512-0</th>\n",
       "      <td>0.594385</td>\n",
       "      <td>0.594385</td>\n",
       "      <td>0.697766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semantic-chunks-90</th>\n",
       "      <td>0.627444</td>\n",
       "      <td>0.627444</td>\n",
       "      <td>0.628548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       precision    recall      ndcg\n",
       "experiment_name                                                     \n",
       "fixed-size-2048-200                     0.841915  0.841915  0.884327\n",
       "fixed-size-2048-0                       0.933036  0.933036  0.882625\n",
       "recursive-2048-0                        0.863806  0.863806  0.873765\n",
       "markdown-header-recursive-2048-200      0.805336  0.805336  0.863841\n",
       "fixed-size-1024-200                     0.767514  0.767514  0.841550\n",
       "markdown-header-recursive-2048-0        0.724237  0.724237  0.838231\n",
       "recursive-2048-200                      0.828538  0.828538  0.835953\n",
       "markdown-header                         0.626389  0.626389  0.811778\n",
       "semantic-chunks-95                      0.744874  0.744874  0.810884\n",
       "fixed-size-1024-0                       0.762517  0.762517  0.797328\n",
       "recursive-1024-0                        0.711180  0.711180  0.791921\n",
       "semantic-chunks-95-recursive-2048-200   0.770040  0.770040  0.779158\n",
       "recursive-1024-200                      0.701689  0.701689  0.774712\n",
       "fixed-size-512-0                        0.696388  0.696388  0.754399\n",
       "fixed-size-512-200                      0.687977  0.687977  0.748491\n",
       "markdown-header-recursive-1024-200      0.702960  0.702960  0.736516\n",
       "recursive-512-0                         0.660700  0.660700  0.732745\n",
       "markdown-header-recursive-512-200       0.643205  0.643205  0.732594\n",
       "recursive-512-200                       0.677771  0.677771  0.731007\n",
       "markdown-header-recursive-1024-0        0.671362  0.671362  0.707776\n",
       "markdown-header-recursive-512-0         0.594385  0.594385  0.697766\n",
       "semantic-chunks-90                      0.627444  0.627444  0.628548"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by ndcg\n",
    "results_view = results.drop(columns=[\"question_type\"]).groupby(\"experiment_name\").mean().sort_values(by=\"ndcg\", ascending=False)\n",
    "results_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "answer_correctness_system_prompt = \"\"\"You are a CORRECTNESS grader; providing the correctness of the given GENERATED ANSWER compared to the given GROUND TRUTH ANSWER.\n",
    "Respond only as a number from 0 to 10 where 0 is the least correct and 10 is the most correct.\n",
    "\n",
    "A few additional scoring guidelines:\n",
    "\n",
    "- Long GENERATED ANSWERS should score equally well as short GENERATED ANSWERS.\n",
    "\n",
    "- CORRECTNESS score should increase as the GENERATED ANSWER matches more accurately with the GROUND TRUTH ANSWER.\n",
    "\n",
    "- CORRECTNESS score should increase as the GENERATED ANSWER covers more parts of the GROUND TRUTH ANSWER accurately.\n",
    "\n",
    "- GENERATED ANSWERS that partially match the GROUND TRUTH ANSWER should score 2, 3, or 4. Higher scores indicate more correctness.\n",
    "\n",
    "- GENERATED ANSWERS that mostly match the GROUND TRUTH ANSWER should get a score of 5, 6, 7, or 8. Higher scores indicate more correctness.\n",
    "\n",
    "- GENERATED ANSWERS that fully match the GROUND TRUTH ANSWER should get a score of 9 or 10. Higher scores indicate more correctness.\n",
    "\n",
    "- GENERATED ANSWERS must be fully accurate and comprehensive to the GROUND TRUTH ANSWER to get a score of 10.\n",
    "\n",
    "- Never elaborate.\"\"\"\n",
    "\n",
    "answer_correctness_user_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"GROUND TRUTH ANSWER: {ground_truth_answer}\n",
    "\n",
    "GENERATED ANSWER: {generated_answer}\n",
    "\n",
    "CORRECTNESS: \"\"\"\n",
    ")\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "generator_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "for experiment_name, questions in gold_dataset.items():\n",
    "    print(\"Evaluating\", experiment_name)\n",
    "    vector_stores[experiment_name].embeddings.show_progress_bar = False\n",
    "    retriever = vector_stores[experiment_name].as_retriever(search_kwargs={\"k\": 10})\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | generator_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    for question_type, testsets in questions.items():\n",
    "        mean_answer_correctness = 0\n",
    "        for testset in testsets:\n",
    "            response = rag_chain.invoke(testset[\"question\"])\n",
    "            answer_correctness_prompt = answer_correctness_user_prompt.format(\n",
    "                ground_truth_answer=testset[\"ground_truth_answer\"], generated_answer=response\n",
    "            )\n",
    "\n",
    "            llm_messages = [\n",
    "                SystemMessage(content=answer_correctness_system_prompt),\n",
    "                HumanMessage(content=answer_correctness_prompt),\n",
    "            ]\n",
    "            response = make_request_with_backoff(llm_messages)\n",
    "\n",
    "            answer_correctness = re_0_10_rating(response.content)\n",
    "            mean_answer_correctness += answer_correctness\n",
    "        mean_answer_correctness /= len(testsets)\n",
    "        print(f\"Experiment: {experiment_name} Question Type: {question_type} Mean Answer Correctness: {mean_answer_correctness}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
